# Rudra â€” Intelligent Voice Assistant ğŸ§ ğŸ™ï¸

Rudra is a **modular, Python-based intelligent voice assistant** designed to run reliably on **Linux systems**.  
The project is built **step-by-step** with a strong emphasis on **architecture, stability, and extensibility**, rather than quick or fragile features.

The long-term vision is to evolve Rudra into an **offline-first, algorithm-driven AI assistant**, capable of system control, memory, and natural interaction across devices.

---

## ğŸ”– Project Status

**Current Stable Milestone:** âœ… **Day 10 â€” System Actions & Intent Abstraction**

Day 10 introduces **safe, enum-driven system control** while preserving Rudraâ€™s stability guarantees.

âœ” Intent â†’ Action abstraction (enum-driven, no strings)  
âœ” Centralized system execution layer  
âœ” Linux-safe application launching  
âœ” Terminal launch fixed (avoids Snap / GLIBC conflicts)  
âœ” Strict separation between NLP, skills, and OS execution  

> ğŸ”’ Day 10 is stable and frozen.

---

## ğŸš€ Features (Implemented)

### âœ… Core Assistant
- Intent-based command processing (enum-driven)
- Modular NLP pipeline
- Short-term & long-term conversational memory
- MySQL-backed persistent storage
- Clean separation of concerns
- Predictable and debuggable execution flow

---

### âœ… Input System (Day 8)
- Voice input using **Google Speech Recognition**
- Text input fallback
- **Push-to-talk** (press ENTER to speak)
- Configurable input mode (voice / text)
- Controlled listening (no always-on microphone)

---

### âœ… Input Intelligence (Day 9)
- Input normalization & validation gate
- Minimum-length and word-count filtering
- Repeat suppression (only for previously accepted inputs)
- Confidence refinement after intent scoring
- Safe handling of unknown intents
- Clear retry prompts (no infinite loops)

---

### âœ… Active Listening & Silence Handling (Day 9)
- Listening state machine (`IDLE â†’ ACTIVE â†’ WAITING`)
- Automatic silence detection
- Context-aware prompts:
  - â€œIâ€™m listening.â€
  - â€œGoing to sleep.â€
- No accidental intent execution during silence
- Natural conversational pacing

---

### âœ… System Actions (Day 10)
- Enum-driven **Intent â†’ Action** mapping
- Centralized `AppRegistry` for allowed actions
- Isolated `SystemExecutor` (OS boundary)
- Supported actions:
  - Open browser
  - Open file manager
  - Open terminal (Linux-safe, Snap-safe)
- No string-based execution
- No direct OS access from skills or NLP layers

---

### âœ… Stability & Logging
- Structured logging using **Loguru**
- Detailed debug traces for:
  - Input validation
  - Intent scoring
  - Confidence decisions
  - Action execution
- Graceful handling of speech, microphone, and OS errors
- Environment-variable based configuration
- Secure `.env` usage (never committed)

---

## ğŸ§  Project Architecture

core/
â”œâ”€â”€ main.py # Entry point
â”œâ”€â”€ assistant.py # Main assistant loop (state-driven)
â”œâ”€â”€ config.py # Input & environment configuration
â”œâ”€â”€ input_controller.py # Centralized input handling
â”‚
â”œâ”€â”€ input/
â”‚ â””â”€â”€ input_validator.py # Input intelligence & repeat control
â”‚
â”œâ”€â”€ speech/
â”‚ â””â”€â”€ google_engine.py # Google Speech Recognition engine
â”‚
â”œâ”€â”€ nlp/
â”‚ â”œâ”€â”€ normalizer.py # Text normalization
â”‚ â”œâ”€â”€ tokenizer.py # Tokenization
â”‚ â””â”€â”€ intent.py # Intent enum definitions
â”‚
â”œâ”€â”€ intelligence/
â”‚ â”œâ”€â”€ intent_scorer.py # Rule-based intent scoring
â”‚ â””â”€â”€ confidence_refiner.py
â”‚
â”œâ”€â”€ skills/
â”‚ â””â”€â”€ basic.py # Skill execution (intent-level only)
â”‚
â”œâ”€â”€ system/
â”‚ â”œâ”€â”€ app_registry.py # Intent â†’ Action registry
â”‚ â””â”€â”€ executor.py # OS-level execution (isolated)
â”‚
â”œâ”€â”€ context/
â”‚ â”œâ”€â”€ short_term.py # Session memory
â”‚ â””â”€â”€ long_term.py # Persistent memory
â”‚
â”œâ”€â”€ storage/
â”‚ â”œâ”€â”€ mysql.py # Database connection
â”‚ â””â”€â”€ models.py # DB models

yaml
Copy code

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.10+
- **Speech Engine:** Google Speech Recognition
- **Database:** MySQL
- **Logging:** Loguru
- **OS Target:** Linux (Ubuntu tested)

---

## â–¶ï¸ Running the Assistant

```bash
# Activate virtual environment
source venv/bin/activate

# Run Rudra
python3 -m core.main
Usage

Press ENTER â†’ speak

Say commands naturally (e.g., open terminal)

Silence is handled automatically

Say exit rudra to quit
```

## ğŸ§­ Roadmap (High Level)
Day 11â€“14: Contextual follow-ups & multi-step commands

Day 15â€“25: Advanced skills & workflows

Day 26â€“40: Memory intelligence & personalization

Day 41â€“60: Offline intent engine & algorithms

Day 61â€“70: Multi-device sync & Raspberry Pi build

## ğŸ“Œ Philosophy
Rudra is not built to demo quickly â€”
it is built to last, scale, and evolve.

Every feature must be:

Predictable

Debuggable

Extendable

Safe to modify later

## ğŸ“œ License
This project is currently for learning, research, and portfolio purposes.
License will be finalized once the core system stabilizes.

Author: Ankesh
Project: Rudra â€” Intelligent Voice Assistant