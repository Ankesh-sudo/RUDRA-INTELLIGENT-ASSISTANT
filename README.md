# Rudra â€” Intelligent Voice Assistant ğŸ§ ğŸ™ï¸

Rudra is a **deterministic, modular, Python-based intelligent assistant framework** designed to run reliably on Linux systems.

It is **not** a quick-demo chatbot.
Rudra is engineered step-by-step with strict architectural rules, safety guarantees, and explainability at every layer.

The long-term vision is an **offline-first, algorithm-driven AI assistant** capable of system control, memory, and natural interaction across devices â€” without black boxes or silent authority.

---

## ğŸ”– Project Status

### âœ… Current Stable Milestone: **Day 38 â€” Voice Explainability Lock**

As of **Day 38**, Rudraâ€™s **core reasoning, memory, persona, and voice layers are fully sealed and auditable**.

Voice (TTS) exists only as a **non-authoritative output channel** and is now **visible in explain traces** without influencing logic or text.

ğŸ”’ **All systems up to Day 38 are complete, tested, and hard-locked.**

---

## ğŸ§± What Is Completed (Day 1 â†’ Day 38)

### ğŸ§± Phase 1 â€” Core Assistant Foundation (Day 1â€“7)
- Deterministic main loop
- Input validation â†’ normalization
- Rule-based intent routing
- Action execution framework
- Global interrupt system (HARD / SOFT / IGNORE)
- Deterministic execution order
- Structured logging
- Test-first discipline

**Result:** No undefined paths. Fully auditable core.

---

### ğŸ§  Phase 2 â€” NLP & Intent Intelligence (Day 8â€“13)
- Tokenization & normalization
- Rule-based intent scoring (no ML)
- Best-intent selection
- Confidence calculation & refinement
- Slot extraction & merging
- Context-aware confidence adjustment
- Clarification loop
- Unknown-intent handling

**Result:** Explainable understanding. Zero black boxes.

---

### ğŸ§  Phase 3 â€” Short-Term Memory (Day 14â€“18)
- Working memory model
- STM lifecycle & eviction
- Context-pack builder
- Threshold-based recall
- Follow-up resolution
- Interrupt-safe lifecycle

**Result:** Conversational continuity without persistence risk.

---

### ğŸ§  Phase 4 â€” Long-Term Memory (Day 19â€“23)
- LTM schema
- Memory classification
- Promotion evaluator
- Explicit consent gate
- User approval flow
- Conflict detection & replacement
- No silent learning

**Result:** Ethical, user-owned memory only.

---

### ğŸ” Phase 5 â€” Read-Only Memory Recall (Day 24)
- Deterministic recall APIs
- Category & confidence filters
- Exact vs contains matching
- Presentation-only formatting

**Result:** Memory is visible, not influential.

---

### ğŸ” Phase 6 â€” Controlled Memory Usage (Day 25)
- Usage modes (OFF / ONCE / SESSION / SCOPED)
- Immutable permits
- Permit expiry
- Single guarded recall entry
- Usage trace
- `explain_last()` / `explain_all()`

**Result:** Memory affects behavior only with permission.

---

### ğŸ§© Phase 7 â€” Opt-In Memory Influence (Day 26)
- Influence contracts
- Immutable influence signals
- Deterministic influence gate
- Explain trace emission

**Result:** Influence exists architecturally but is inert.

---

### ğŸŸ¦ Day 27â€“30 â€” Preference System (Final)
- Whitelisted preference schema
- Deterministic resolution
- Preview â†’ confirm â†’ apply enforcement
- Explicit scope & expiry
- Persona-safe boundary lock

**Result:** Preferences affect wording only. System permanently frozen.

---

### ğŸŸ¦ Day 31â€“33 â€” Maahi Persona (Text-Only)
- Persona adapter & contract
- Semantic guard
- Suffix-only expressiveness
- Deterministic selection
- Affection Tier-A hard cap
- No memory, intent, or preference access

**Result:** Persona feels human but has zero authority.

---

### ğŸŸ¦ Day 34â€“35 â€” TTS Architecture Lock
- Final-text-only TTS contract
- Abstract engine interface
- No-op engine
- Closed registry
- Interrupt-safe adapter
- Tests proving TTS cannot affect text

**Result:** Voice is optional, powerless, and replaceable.

---

### ğŸŸ¦ Day 36â€“37 â€” Persona â†” Voice Sealing
- Immutable PersonaProfile
- Fingerprinted persona identity
- FinalResponseEnvelope (sealed)
- Persona applied exactly once
- Voice consumes envelope only
- Removability safety proofs

**Result:** Persona and voice are fully isolated and non-evolving.

---

### ğŸŸ¦ Day 38 â€” Voice Explainability
- TTS execution surfaced in explain traces
- Voice status: requested / skipped / failed / ok
- No control-flow or text impact

**Result:** Voice is explainable, not powerful.

---

## ğŸ§  Architecture Overview

```text
core/
â”œâ”€â”€ main.py
â”œâ”€â”€ assistant.py
â”œâ”€â”€ input_controller.py
â”‚
â”œâ”€â”€ input/
â”œâ”€â”€ speech/
â”œâ”€â”€ nlp/
â”œâ”€â”€ intelligence/
â”œâ”€â”€ actions/
â”œâ”€â”€ skills/
â”œâ”€â”€ context/
â”œâ”€â”€ influence/
â”œâ”€â”€ persona/
â”œâ”€â”€ tts/
â”œâ”€â”€ explain/
â””â”€â”€ tests/
```

---

## ğŸ› ï¸ Tech Stack

- **Language:** Python 3.10 / 3.11
- **OS Target:** Linux (Ubuntu tested)
- **Speech Engine:** Google Speech Recognition
- **Database:** MySQL
- **ORM:** SQLAlchemy
- **Logging:** Loguru
- **Testing:** Pytest

---

## â–¶ï¸ Running Rudra

```bash
source venv/bin/activate
python3 -m core.main
```

---

## ğŸ§­ Roadmap

- **Day 39â€“40:** Voice failure isolation & permanent freeze
- **Day 41â€“55:** Real assistant capabilities (OS control, automation, devices)
- **Day 56â€“70:** Safe, explainable learning & ML

Persona has **zero role** beyond presentation.

---

## ğŸ“Œ Philosophy

Rudra is built for:
- Determinism
- Explainability
- Auditability
- Long-term evolution

No shortcuts.
No magic.
No silent decisions.

---

**Author:** Ankesh  
**Project:** Rudra â€” Intelligent Voice Assistant