# Rudra â€” Intelligent Voice Assistant ğŸ§ ğŸ™ï¸

Rudra is a modular, Python-based intelligent voice assistant designed to run reliably on Linux systems.
The project is built step-by-step with a strong emphasis on architecture, stability, and extensibility, rather than quick or fragile features.

The long-term vision is to evolve Rudra into an offline-first, algorithm-driven AI assistant, capable of system control, memory, and natural interaction across devices.

## ğŸ”– Project Status

Current Stable Milestone: âœ… Day 12 â€” Argument Extraction & Safe System Control

Day 12 completes Rudraâ€™s action execution pipeline, making system commands contextual, validated, and confidence-gated.

âœ” Argument extraction for system commands
âœ” Intent â†’ Argument â†’ Action flow
âœ” Confidence-based execution gating
âœ” Safe rejection of ambiguous commands
âœ” MySQL persistence restored & verified
âœ” .env loading hardened for production

ğŸ”’ Day 12 is complete, tested, and locked.

## ğŸš€ Features (Implemented)
### âœ… Core Assistant

Enum-driven intent-based command processing

Modular NLP pipeline (no hardcoded logic)

Short-term & long-term conversational memory

MySQL-backed persistent storage

Clean separation of concerns

Predictable, debuggable execution flow

### âœ… Input System (Day 8)

Voice input using Google Speech Recognition

Text input fallback

Push-to-talk (press ENTER to speak)

Configurable input mode (voice / text)

Controlled listening (no always-on microphone)

### âœ… Input Intelligence (Day 9)

Input normalization & validation gate

Minimum-length and word-count filtering

Repeat suppression (only for previously accepted inputs)

Confidence refinement after intent scoring

Safe handling of unknown intents

Clear retry prompts (no infinite loops)

### âœ… Active Listening & Silence Handling (Day 9)

Listening state machine (IDLE â†’ ACTIVE â†’ WAITING)

Automatic silence detection

Context-aware prompts:

â€œIâ€™m listening.â€

â€œGoing to sleep.â€

No accidental intent execution during silence

Natural conversational pacing

### âœ… System Actions (Day 10)

Enum-driven Intent â†’ Action abstraction

Centralized system execution layer

Linux-safe application launching

Terminal launch hardened (Snap / GLIBC safe)

No direct OS access from NLP or skills

Strict OS boundary enforcement

### âœ… Argument Extraction & Action Gating (Day 12)

Context-aware argument extraction:

URLs

File paths

Directories

Search queries

Validation before execution

Confidence-based execution gate:

High confidence â†’ execute

Ambiguous â†’ reject safely

Low confidence â†’ request rephrase

Deterministic behavior (no guessing)

### âœ… Stability, Persistence & Logging

Structured logging using Loguru

Detailed debug traces for:

Input validation

Intent scoring

Confidence decisions

Argument extraction

Action execution

Graceful handling of speech, microphone, and OS errors

Secure .env usage (never committed)

Explicit .env loading for production reliability

## ğŸ§  Project Architecture
core/
â”œâ”€â”€ main.py                  # Entry point
â”œâ”€â”€ assistant.py             # Main assistant loop (state-driven)
â”œâ”€â”€ input_controller.py      # Centralized input handling
â”‚
â”œâ”€â”€ input/
â”‚   â””â”€â”€ input_validator.py   # Input intelligence & repeat control
â”‚
â”œâ”€â”€ speech/
â”‚   â””â”€â”€ google_engine.py     # Google Speech Recognition engine
â”‚
â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ normalizer.py        # Text normalization
â”‚   â”œâ”€â”€ tokenizer.py         # Tokenization
â”‚   â”œâ”€â”€ intent.py            # Intent enum definitions
â”‚   â””â”€â”€ argument_extractor.py# Day 12 argument extraction
â”‚
â”œâ”€â”€ intelligence/
â”‚   â”œâ”€â”€ intent_scorer.py     # Rule-based intent scoring
â”‚   â””â”€â”€ confidence_refiner.py
â”‚
â”œâ”€â”€ actions/
â”‚   â””â”€â”€ action_executor.py   # Confidence-gated execution layer
â”‚
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ basic.py             # Non-system skills
â”‚   â””â”€â”€ system_actions.py    # System action handlers
â”‚
â”œâ”€â”€ context/
â”‚   â”œâ”€â”€ short_term.py        # Session memory
â”‚   â””â”€â”€ long_term.py         # Persistent memory (MySQL)
â”‚
â”œâ”€â”€ storage/
â”‚   â”œâ”€â”€ mysql.py             # Database connection
â”‚   â””â”€â”€ models.py            # DB models

## ğŸ› ï¸ Tech Stack

Language: Python 3.10+

Speech Engine: Google Speech Recognition

Database: MySQL

ORM: SQLAlchemy

Logging: Loguru

OS Target: Linux (Ubuntu tested)

## â–¶ï¸ Running the Assistant
### Activate virtual environment
```bash
source venv/bin/activate
```

### Run Rudra
```bash
python3 -m core.main
```

Usage

Press ENTER â†’ speak

Say commands naturally (e.g., open browser github)

Silence is handled automatically

Say exit rudra to quit

## ğŸ§­ Roadmap (High Level)

Day 13â€“14: Follow-up context (â€œopen itâ€, â€œdo that againâ€)

Day 15â€“25: Advanced skills & workflows

Day 26â€“40: Memory intelligence & personalization

Day 41â€“60: Offline intent engine & algorithms

Day 61â€“70: Multi-device sync & Raspberry Pi build

## ğŸ“Œ Philosophy

Rudra is not built to demo quickly â€”
it is built to last, scale, and evolve.

Every feature must be:

Predictable

Debuggable

Extendable

Safe to modify later

No shortcuts. No magic. No fragile abstractions.

## ğŸ“œ License

This project is currently for learning, research, and portfolio purposes.
License will be finalized once the core system stabilizes.

Author: Ankesh
Project: Rudra â€” Intelligent Voice Assistant